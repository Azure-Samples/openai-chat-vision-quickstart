# Can be "azure", "github", or "local"
OPENAI_HOST="azure"
# For Azure, the model name should actually be the deployment name
OPENAI_MODEL="gpt-4o"

# For Azure host:
AZURE_OPENAI_API_VERSION=""
AZURE_OPENAI_ENDPOINT="https://YOUR-ENDPOINT-HERE.openai.azure.com/"

# For GitHub models:
GITHUB_MODELS_ENDPOINT="https://models.inference.ai.azure.com"

# For local models, like Ollama/llamafile:
LOCAL_OPENAI_ENDPOINT="http://localhost:8080/v1"