{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with PDF page images\n",
    "\n",
    "**If you're looking or the web application, check the src/ folder.** \n",
    "\n",
    "This notebook demonstrates how to convert PDF pages to images and send them to a vision model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to OpenAI\n",
    "\n",
    "The following code connects to OpenAI, either using an Azure OpenAI account, GitHub models, or local Ollama model. See the README for instruction on configuring the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GitHub Models with GITHUB_TOKEN as key\n",
      "Using model openai/gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import azure.identity\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "openai_host = os.getenv(\"OPENAI_HOST\", \"github\")\n",
    "\n",
    "if openai_host == \"github\":\n",
    "    print(\"Using GitHub Models with GITHUB_TOKEN as key\")\n",
    "    openai_client = openai.OpenAI(\n",
    "        api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    "        base_url=\"https://models.github.ai/inference\",\n",
    "    )\n",
    "    model_name = os.getenv(\"OPENAI_MODEL\", \"openai/gpt-4o\")\n",
    "elif openai_host == \"local\":\n",
    "    print(\"Using local OpenAI-compatible API with no key\")\n",
    "    openai_client = openai.OpenAI(api_key=\"no-key-required\", base_url=os.environ[\"LOCAL_OPENAI_ENDPOINT\"])\n",
    "    model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "elif openai_host == \"azure\" and os.getenv(\"AZURE_OPENAI_KEY_FOR_CHATVISION\"):\n",
    "    # Authenticate using an Azure OpenAI API key\n",
    "    # This is generally discouraged, but is provided as a convenience\n",
    "    print(\"Using Azure OpenAI with key\")\n",
    "    openai_client = openai.OpenAI(\n",
    "        base_url=os.environ[\"AZURE_OPENAI_ENDPOINT\"] + \"/openai/v1/\",\n",
    "        api_key=os.environ[\"AZURE_OPENAI_KEY_FOR_CHATVISION\"],\n",
    "    )\n",
    "    # This is actually the deployment name, not the model name\n",
    "    model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "elif openai_host == \"azure\" and os.getenv(\"AZURE_OPENAI_ENDPOINT\"):\n",
    "    tenant_id = os.environ[\"AZURE_TENANT_ID\"]\n",
    "    print(\"Using Azure OpenAI with Azure Developer CLI credential for tenant id\", tenant_id)\n",
    "    default_credential = azure.identity.AzureDeveloperCliCredential(tenant_id=tenant_id)\n",
    "    token_provider = azure.identity.get_bearer_token_provider(\n",
    "        default_credential, \"https://cognitiveservices.azure.com/.default\"\n",
    "    )\n",
    "    openai_client = openai.OpenAI(\n",
    "        base_url=os.environ[\"AZURE_OPENAI_ENDPOINT\"] + \"/openai/v1/\",\n",
    "        api_key=token_provider,\n",
    "    )\n",
    "    # This is actually the deployment name, not the model name\n",
    "    model_name = os.getenv(\"OPENAI_MODEL\", \"gpt-4o\")\n",
    "\n",
    "print(f\"Using model {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDFs to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF, Pillow\n",
      "Successfully installed Pillow-11.3.0 PyMuPDF-1.26.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from PIL import Image\n",
    "\n",
    "filename = \"plants.pdf\"\n",
    "doc = pymupdf.open(filename)\n",
    "for i in range(doc.page_count):\n",
    "    doc = pymupdf.open(filename)\n",
    "    page = doc.load_page(i)\n",
    "    pix = page.get_pixmap()\n",
    "    original_img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    original_img.save(f\"page_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send images to vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "\n",
    "def open_image_as_base64(filename):\n",
    "    with open(filename, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "    image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "    return f\"data:image/png;base64,{image_base64}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These pages list a variety of plants offered by The Watershed Nursery. Here's a summary of the plant types listed on the individual pages:\n",
      "\n",
      "---\n",
      "\n",
      "### **Page 1:**\n",
      "\n",
      "**Annuals:**\n",
      "- _Centromadia pungens_ (Common tarweed)\n",
      "- _Epilobium densiflorum_ (Dense Spike-primrose)\n",
      "- _Eschscholzia caespitosa_ (Tufted Poppy)\n",
      "- _Eschscholzia californica_ (California Poppy)\n",
      "- _Eschscholzia californica 'Purple Gleam'_ (Purple Gleam Poppy)\n",
      "- _Eschscholzia californica var. maritima_ (Coastal California Poppy)\n",
      "- _Madia elegans_ (Tarweed)\n",
      "- _Mentzelia lindleyi_ (Lindley's Blazing Star)\n",
      "- _Symphyotrichum subulatum_ (Slim marsh aster)\n",
      "- _Trichostema lanceolatum_ (Vinegar weed)\n",
      "\n",
      "**Bulbs:**\n",
      "- _Brodiaea californica_ (California brodiaea)\n",
      "- _Chlorogalum pomeridianum_ (Soap plant)\n",
      "- _Epipactis gigantea_ (Stream orchid)\n",
      "- _Wyethia angustifolia_ (Narrowleaf mule ears)\n",
      "- _Wyethia mollis_ (Woolly Mule's Ear)\n",
      "\n",
      "**Grasses:**\n",
      "- _Agrostis pallens_ (Thingrass)\n",
      "- _Anthoxanthum occidentale_ (Vanilla grass)\n",
      "- _Bouteloua gracilis_ (Blue grama)\n",
      "\n",
      "---\n",
      "\n",
      "### **Page 2:**\n",
      "\n",
      "**Grasses:**\n",
      "- _Bromus laevipes_ (Woodland Brome)\n",
      "- _Danthonia californica_ (California oatgrass)\n",
      "- _Festuca californica_ (California fescue)\n",
      "- _Festuca idahoensis_ (Idaho fescue)\n",
      "- _Festuca rubra_ (Red fescue)\n",
      "- _Sporobolus airoides_ (Alkali sacaton)\n",
      "- _Stipa cernua_ (Nodding needlegrass)\n",
      "- _Stipa lepida_ (Foothill needlegrass)\n",
      "- _Stipa pulchra_ (Purple needlegrass)\n",
      "\n",
      "**Perennials:**\n",
      "- _Achillea millefolium_ (Yarrow)\n",
      "- _Ambrosia chamissonis_ (Silvery beachweed)\n",
      "- _Anemopsis californica_ (Yerba mansa)\n",
      "- _Angelica hendersonii_ (Coast Angelica)\n",
      "- _Apocynum cannabinum_ (Hemp Dogbane)\n",
      "- _Aquilegia eximia_ (Serpentine columbine)\n",
      "- _Aristolochia californica_ (California Dutchman's Pipe)\n",
      "\n",
      "---\n",
      "\n",
      "### **Page 3:**\n",
      "\n",
      "**Perennials:**\n",
      "- _Armeria maritima_ (Sea thrift)\n",
      "- _Artemisia douglasiana_ (Mugwort)\n",
      "- _Asarum caudatum_ (Wild ginger)\n",
      "- _Asclepias californica_ (California Milkweed)\n",
      "- _Asclepias eriocarpa_ (Woolypod milkweed)\n",
      "- _Asclepias fascicularis_ (Narrow leaf milkweed)\n",
      "- _Asclepias speciosa_ (Showy milkweed)\n",
      "- _Atriplex leucophylla_ (Beach Salt Bush)\n",
      "- _Baccharis glutinosa_ (Marsh baccharis)\n",
      "- _Bidens laevis_ (Smooth Bur Marigold)\n",
      "- _Bolboschoenus maritimus_ (Cosmopolitan bulrush)\n",
      "- _Calystegia occidentalis_ (Western chaparral)\n",
      "- _Calystegia purpurata ssp. saxicola_ (Bodega Morning Glory)\n",
      "- _Camissoniopsis cheiranthifolia_ (Beach primrose)\n",
      "- _Campanula rotundifolia_ (Round Leaf Harebell)\n",
      "- _Carex athrostachya_ (Slenderbeak sedge)\n",
      "- _Carex barbarae_ (Santa Barbara sedge)\n",
      "\n",
      "---\n",
      "\n",
      "This listing provides a complete overview of the plants in three categories: Annuals, Bulbs, Grasses, and Perennials across all 3 pages.\n"
     ]
    }
   ],
   "source": [
    "user_content = [{\"text\": \"What plants are listed on these pages?\", \"type\": \"text\"}]\n",
    "# Process just the first few pages, as processing all doc.page_count pages is slow\n",
    "for i in range(3):\n",
    "    user_content.append({\"image_url\": {\"url\": open_image_as_base64(f\"page_{i}.png\")}, \"type\": \"image_url\"})\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=model_name, messages=[{\"role\": \"user\", \"content\": user_content}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
